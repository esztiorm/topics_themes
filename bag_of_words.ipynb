{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv('strata_scheduled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class preproc(object):\n",
    "    # need to put in check that dataframe has more than one row\n",
    "    def __init__(self,dataframe,*col_names):\n",
    "    # Load references for use in cleaning.\n",
    "        self.df = dataframe\n",
    "        self.col_names = col_names\n",
    "        self.dict_en = enchant.Dict('en_US')\n",
    "        self.tzer = nltk.RegexpTokenizer(r\"\\w+(?=n't)|n't|\\w+(?=')|'\\w+|\\w+|-\")\n",
    "        self.stopEng = set(nltk.corpus.stopwords.words('english'))\n",
    "        #self.p_stemmer = nltk.PorterStemmer()\n",
    "    \n",
    "    def token_split(self):\n",
    "        \"\"\"\n",
    "        Tokenize based on nltk RegexpTokenizer.\n",
    "        Split into words and non-words based on PyEnchant English dict and being alphanumeric.\n",
    "        Filter out stop words.\n",
    "        \"\"\"\n",
    "        for column in self.col_names:\n",
    "            new_column = pd.Series(index=self.df.index, name = (column + '_bow'))\n",
    "            for i,item in enumerate(self.df[column]):\n",
    "                tokens = self.tzer.tokenize(item.lower()) # make everything lowercase\n",
    "                words = [t for t in tokens if self.dict_en.check(t)]\n",
    "                non_words = [t for t in tokens if not self.dict_en.check(t) and len(t)>1]\n",
    "                filtered = filter(lambda word: word not in self.stopEng, words)\n",
    "                #stemmed = [self.p_stemmer.stem(i.lower()) for i in filtered]  \n",
    "                new_column[new_column.index[i]] = filtered\n",
    "            self.df = self.df.join(new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed = preproc(raw,'description','abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed.token_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
